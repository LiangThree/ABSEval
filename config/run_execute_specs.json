[
  {
    "db_path": "data/database/script.db",
    "model_conf_path": "config/model_config_docker.yaml",
    "category": [ "ALL" ],
    "others": [
        "Arts and Entertainment", "Computers and Electronics", "Education and Communications",
          "Food and Entertaining","Health", "Hobbies and Crafts", "Holidays and Traditions",
          "Home and Garden", "Sports and Fitness", "Travel"
    ],
    "inference_model_repo_id": [
        "meta/llama2-7b-chat",
        "baichuan-inc/Baichuan-13B-Chat",
        "baichuan-inc/Baichuan2-13B-Chat",
        "qwen/Qwen-7B-Chat",
        "qwen/Qwen-14B-Chat",
        "THUDM/chatglm3-6b",
        "mistralai/Mistral-7B-Instruct-v0.1",
        "mistralai/Mistral-7B-Instruct-v0.2",
        "meta/llama2-13b-chat",
        "WizardLM/WizardLM-13B-V1.2",
        "tiiuae/falcon-40b-instruct",
        "qwen/Qwen-72B-Chat",
        "meta/Llama-2-70b-chat",
        "lmsys/vicuna-7b-v1.5",
        "lmsys/vicuna-13b-v1.5",
        "mistralai/Mistral-8x7B-Instruct-v0.1",
        "meta/llama3-8b-instruct"
    ],
    "metric_conf": {
      "metric_name": "model_metric",
      "model_repo_id": [
        "qwen/Qwen-110B-Chat"
      ],
      "acceleration_method": "vllm",
      "eval_execute_format": "path:data/metrics/execute_prompt.txt"
    }
  }
]
